# Convert the optimal setting to numerical values
design.confirm <- data.frame(ntree = rep(1000,3),
mtry = rep(2,3),
replace = rep(0,3),
nodesize = rep(11,3),   # Now hard-code every cell to be 1
classwt = rep(0.5,3),
cutoff = rep(0.8,3),
maxnodes = rep(10,3))
head(design.confirm)
# Lastly, run cv.rf() three times with optimal setting (with numerical data) to confirm
confirm.result <- cv.rf(design.confirm, y, X)
head(confirm.result)
summary(result)
# import dataset Cardiovascular
load("Data/cardiovascular.Rdata")
# Lastly, run cv.rf() three times with optimal setting (with numerical data) to confirm
confirm.result <- cv.rf(design.confirm, y, X)
head(confirm.result)
summary(confirm.result$CV)
confirm.result$CV
mean(confirm.result$CV)
confirm.result$CV
# Analysis of Residuals
cv.res <- cv.model.bic$residuals
cv.fit <- cv.model.bic$fitted.values
par(mfrow = c(1,3))
qqnorm(cv.res)
qqline(cv.res)
plot(cv.fit,cv.res, main = "Residuals vs Fitted Values",
xlab = "Predicted", ylab = "Residuals")
N <- nrow(result)
plot(x = 1:N, y = cv.res, xlab = "Run Order",
ylab = "Residuals")
# Lastly, run cv.rf() three times with optimal setting (with numerical data) to confirm
confirm.result <- cv.rf(design.confirm, y, X)
confirm.result$CV
knitr::opts_chunk$set(echo = TRUE)
library(AlgDesign)
library(FrF2)
library(corrplot)
library(randomForest)
factors <- list(ntree = c(100, 1000),
mtry = c(2, 6),
replace = c(0, 1),
nodesize = c(1,11),
classwt = c(0.5, 0.9),
cutoff = c(0.2, 0.8),
maxnodes = c(10, 1000))
my.design <- FrF2(nruns = 32, nfactors = 7, randomize = F, factor.names = factors)
print(my.design)
design.info(my.design)$catlg.entry
design.info(my.design)$aliased
# Create a full design for 7 factors each with 2 levels
full.design <- FrF2(nruns = 128, nfactors = 7, randomize = F, factor.names = factors)
# Consider a model with 35 runs
alternative.design <- optFederov(~.^2,
full.design, nTrials = 32, nRepeats = 1000)
print.data.frame(alternative.design$design)
# Visualize the aliasing in the design.
FD.alt <- (desnum(my.design)) # Extract the design.
# Create the model matrix including main effects and two-factor interactions.
FX.alt <- model.matrix(~., data.frame(FD.alt))
# Create color map on pairwise correlations.
contrast.vectors.correlations.alt <- cor(FX.alt)
corrplot(contrast.vectors.correlations.alt, type = "full", addgrid.col = "gray",
tl.col = "black", tl.srt = 90, method = "color", tl.cex=0.5)
# Visualize the aliasing in the design.
OD.alt <- alternative.design$design # Extract the design.
# Convert factors to -1 and 1
OD.alt <- sapply(OD.alt,function(x)(as.integer(x) -1.5)*2 )
OX.alt <- model.matrix(~., data.frame(OD.alt))
# Create color map on pairwise correlations.
contrast.vectors.correlations.alt <- cor(OX.alt)
corrplot(contrast.vectors.correlations.alt, type = "full", addgrid.col = "gray",
tl.col = "black", tl.srt = 90, method = "color", tl.cex=0.5)
# We need to include the intercept when computing the VIF.
X.alt <- model.matrix(~., data.frame(OD.alt))
# Variance-covariance matrix of 46-run design. Assuming sigma^2 = 1
var.eff.one <- diag(solve(t(X.alt)%*%X.alt))
# Set the left margin of plot be 1
par(oma=c(0,1,0,0))
#create horizontal bar chart to display each VIF value
barplot(nrow(X.alt)*var.eff.one, main = "VIF Values", horiz = TRUE, col = "cyan", las=1, cex.names=0.4, xlim = c(0, 6))
#add vertical line at 5
abline(v = 5, lwd = 3, lty = 2)
# Create the model matrix including main effects and two-factor interactions.
FX.alt <- model.matrix(~.^2-1, data.frame(FD.alt))
# Create color map on pairwise correlations.
contrast.vectors.correlations.alt <- cor(FX.alt)
corrplot(contrast.vectors.correlations.alt, type = "full", addgrid.col = "gray",
tl.col = "black", tl.srt = 90, method = "color", tl.cex=0.5)
OX.alt <- model.matrix(~.^2-1, data.frame(OD.alt))
# Create color map on pairwise correlations.
contrast.vectors.correlations.alt <- cor(OX.alt)
corrplot(contrast.vectors.correlations.alt, type = "full", addgrid.col = "gray",
tl.col = "black", tl.srt = 90, method = "color", tl.cex=0.5)
# We need to include the intercept when computing the VIF.
X.alt <- model.matrix(~.^2, data.frame(OD.alt))
# Variance-covariance matrix of 46-run design. Assuming sigma^2 = 1
var.eff.one <- diag(solve(t(X.alt)%*%X.alt))
# Set the left margin of plot be 1
par(oma=c(0,1,0,0))
#create horizontal bar chart to display each VIF value
barplot(nrow(X.alt)*var.eff.one, main = "VIF Values", horiz = TRUE, col = "cyan", las=1, cex.names=0.4, xlim = c(0, 6))
#add vertical line at 5
abline(v = 5, lwd = 3, lty = 2)
# We compare the run size of each runs for both designs
summary(as.data.frame(my.design))
summary(alternative.design$design)
table2 <- read.csv("Data/Alternative_Experimental_Design.csv")
head(table2)
# Convert factors to -1 and 1
table2 <- sapply(table2,function(x)(as.integer(as.factor(x)) -2) )
X.alt <- model.matrix(~.^2-1, data.frame(table2[,-1]))
# Create color map on pairwise correlations.
contrast.vectors.correlations.alt <- cor(X.alt)
corrplot(contrast.vectors.correlations.alt, type = "full", addgrid.col = "gray",
tl.col = "black", tl.srt = 90, method = "color", tl.cex=0.5)
# import function cv.rf(design, y, X)
source("CrossValidation_RandomForest/CrossValidation_RF.R")
# import dataset Cardiovascular
load("Data/cardiovascular.Rdata")
# convert the design from factor to numerical values
design.numerical <- as.data.frame(sapply(alternative.design$design, function(x) as.numeric(as.character(x))))
# randomize the run order
design.randomized <- design.numerical[sample(1:nrow(design.numerical)),]
head(design.randomized)
result <- cv.rf(design.randomized, y, X)
# save a copy of result thus no need to run cv.rf again
result.copy <- result
print(result)
# Converting numerical variables back to factors
str(result)
result[,c("ntree","mtry","replace",
"nodesize","classwt","cutoff","maxnodes")] <- lapply(result[,c("ntree","mtry","replace",
"nodesize","classwt","cutoff","maxnodes")],factor)
# Re-encoding Factors
levels(result$ntree) = c(-1,1)
levels(result$mtry) = c(-1,1)
levels(result$replace) = c(-1,1)
levels(result$nodesize) = c(-1,1)
levels(result$classwt) = c(-1,1)
levels(result$cutoff) = c(-1,1)
levels(result$maxnodes) = c(-1,1)
result <- as.data.frame(sapply(result, function(x) as.numeric(as.character(x))))
head(result)
# Running Linear Model
cv.model <- lm(CV~.^2, data=result.copy)
summary(cv.model)
# # Running Reduced Model
# cv.model2 <- lm(CV~(classwt*cutoff+classwt*maxnodes + mtry), data = result)
# summary(cv.model2)
library(leaps)
Best_Subset <- regsubsets(CV~.^2, data = result,
nbest = 1, nvmax=NULL,
force.in = NULL, force.out=NULL,
method = "exhaustive",
really.big=F)
summary_best_subset <- summary(Best_Subset)
plot(summary_best_subset$bic, xlab = "Number of Variables", ylab = "BIC", type = "l")
min = which.min(summary_best_subset$bic)
points(min, summary_best_subset$bic[min], col = "red", cex = 2, pch = 20)
### Select Model with least BIC score
# We first select the best model according to BIC.
modelwith.minimum.BIC <- which.min(summary_best_subset$bic)
best.model <- summary_best_subset$which[modelwith.minimum.BIC,][-1]
# Only keep the predictors are indicated by ‘TRUE’ and our response 'goldDiff'
keep <- names(best.model[best.model==T])
# Print the selected factors
a <- paste(keep,sep=" ",collapse=" + ")
a
# construct a reduced model based on BIC criteria
cv.model.bic <- lm(CV~mtry + nodesize + classwt + cutoff + maxnodes + ntree:mtry + ntree:nodesize + ntree:maxnodes + mtry:replace + mtry:nodesize + mtry:classwt + mtry:cutoff + mtry:maxnodes + replace:maxnodes + nodesize:cutoff + classwt:cutoff + classwt:maxnodes + cutoff:maxnodes, data=result)
# T-test
summary(cv.model.bic)
# Only keep significant factors, run a reduced model since we fever model with less predictors
cv.model.bic <- lm(CV~ nodesize + classwt + cutoff + maxnodes + ntree:mtry + ntree:nodesize + mtry:classwt + classwt:cutoff + classwt:maxnodes, data=result)
# T-test
summary(cv.model.bic)
# Analysis of Residuals
cv.res <- cv.model.bic$residuals
cv.fit <- cv.model.bic$fitted.values
par(mfrow = c(1,3))
qqnorm(cv.res)
qqline(cv.res)
plot(cv.fit,cv.res, main = "Residuals vs Fitted Values",
xlab = "Predicted", ylab = "Residuals")
N <- nrow(result)
plot(x = 1:N, y = cv.res, xlab = "Run Order",
ylab = "Residuals")
obj_func <- function(x){
pred.y <- 0.619459 + 0.012674 * x[4] - 0.054355 * x[5] + 0.025474 * x[6] + 0.015617*x[7] + -0.016947*x[1]*x[2] + 0.010542*x[1]*x[4]+ 0.013876 *x[2]*x[5] + 0.019116 *x[5]*x[6] + 0.033989 *x[5]*x[7]
return(-1*pred.y) # Because the 'optim' function minimizes.
}
# First, use optim() to find the optimal setting according to our model
optim(par = c(-1, -1, -1, -1,-1,-1,-1), fn = obj_func, lower = -1, upper = 1, method = "L-BFGS-B")
# Then, construct a dataframe of 7 columns, 1 row, with the optimal setting above
design.confirm <- data.frame(ntree =1,
mtry = -1,
replace = -1,
nodesize = 1,
classwt = -1,
cutoff = 1,
maxnodes = -1)
head(design.confirm)
# Then, Get the prediction interval of the optimal setting based on our model
predict(cv.model.bic, newdata = design.confirm, interval = "predict")
# Convert the optimal setting to numerical values
design.confirm <- data.frame(ntree = rep(1000,3),
mtry = rep(2,3),
replace = rep(0,3),
nodesize = rep(11,3),
classwt = rep(0.5,3),
cutoff = rep(0.8,3),
maxnodes = rep(10,3))
head(design.confirm)
# Lastly, run cv.rf() three times with optimal setting (with numerical data) to confirm
confirm.result <- cv.rf(design.confirm, y, X)
confirm.result$CV
attach(result)
# Running Linear Model
cv.model <- lm(CV~ntree+mtry+replace+nodesize+classwt+cutoff+maxnodes)
summary(cv.model)
# Running Reduced Model
cv.model2 <- lm(CV~classwt+cutoff)
summary(cv.model2)
# Analysis of Residuals
cv.res <- cv.model2$residuals
cv.fit <- cv.model2$fitted.values
par(mfrow = c(1,3))
qqnorm(cv.res)
qqline(cv.res)
plot(cv.fit,cv.res, main = "Residuals vs Fitted Values",
xlab = "Predicted", ylab = "Residuals")
N <- nrow(result)
plot(x = 1:N, y = cv.res, xlab = "Run Order",
ylab = "Residuals")
# construct a reduced model based on BIC criteria
cv.model.bic <- lm(CV~classwt + cutoff + maxnodes + classwt:cutoff + classwt:maxnodes, data=result)
# T-test
summary(cv.model.bic)
# Analysis of Residuals
cv.res <- cv.model.bic$residuals
cv.fit <- cv.model.bic$fitted.values
par(mfrow = c(1,3))
qqnorm(cv.res)
qqline(cv.res)
plot(cv.fit,cv.res, main = "Residuals vs Fitted Values",
xlab = "Predicted", ylab = "Residuals")
N <- nrow(result)
plot(x = 1:N, y = cv.res, xlab = "Run Order",
ylab = "Residuals")
# # Only keep significant factors, run a reduced model since we fever model with less predictors
# cv.model.bic <- lm(CV~ nodesize + classwt + cutoff + maxnodes + ntree:mtry + ntree:nodesize + mtry:classwt + classwt:cutoff + classwt:maxnodes, data=result)
# # T-test
# summary(cv.model.bic)
obj_func <- function(x){
pred.y <- 0.622765  - 0.048193 * x[5] + 0.028372 * x[6] + 0.015964*x[7] + 0.023461 *x[5]*x[6] + 0.037590 *x[5]*x[7]
return(-1*pred.y) # Because the 'optim' function minimizes.
}
# First, use optim() to find the optimal setting according to our model
optim(par = c(-1, -1, -1, -1,-1,-1,-1), fn = obj_func, lower = -1, upper = 1, method = "L-BFGS-B")
# Then, construct a dataframe of 7 columns, 1 row, with the optimal setting above
design.confirm <- data.frame(ntree = -1,
mtry = -1,
replace = -1,
nodesize = -1,
classwt = -1,
cutoff = 1,
maxnodes = -1)
head(design.confirm)
# Then, Get the prediction interval of the optimal setting based on our model
predict(cv.model.bic, newdata = design.confirm, interval = "predict")
# Convert the optimal setting to numerical values
design.confirm <- data.frame(ntree = rep(100,3),
mtry = rep(2,3),
replace = rep(0,3),
nodesize = rep(1,3),
classwt = rep(0.5,3),
cutoff = rep(0.8,3),
maxnodes = rep(10,3))
head(design.confirm)
# Lastly, run cv.rf() three times with optimal setting (with numerical data) to confirm
confirm.result <- cv.rf(design.confirm, y, X)
confirm.result$CV
mean(confirm.result$CV)
# Convert factors to -1 and 1
table2 <- sapply(table2,function(x)(as.integer(as.factor(x)) -2) )
table2[,3][table2[,3]==0] <- 1
table2
table2 <- read.csv("Data/Alternative_Experimental_Design.csv")
head(table2)
# Convert factors to -1 and 1
table2 <- sapply(table2,function(x)(as.integer(as.factor(x)) -2) )
table2[,3][table2[,3]==0] <- 1
X.alt <- model.matrix(~.^2-1, data.frame(table2[,-1]))
# Create color map on pairwise correlations.
contrast.vectors.correlations.alt <- cor(X.alt)
corrplot(contrast.vectors.correlations.alt, type = "full", addgrid.col = "gray",
tl.col = "black", tl.srt = 90, method = "color", tl.cex=0.5)
knitr::opts_chunk$set(echo = TRUE)
library(AlgDesign)
library(FrF2)
library(corrplot)
library(randomForest)
# We need to include the intercept when computing the VIF.
X.alt <- model.matrix(~.^2, data.frame(table2[,-1]))
table2 <- read.csv("Data/Alternative_Experimental_Design.csv")
head(table2)
# Convert factors to -1 and 1
table2 <- sapply(table2,function(x)(as.integer(as.factor(x)) -2) )
table2[,3][table2[,3]==0] <- 1
X.alt <- model.matrix(~.^2-1, data.frame(table2[,-1]))
# Create color map on pairwise correlations.
contrast.vectors.correlations.alt <- cor(X.alt)
corrplot(contrast.vectors.correlations.alt, type = "full", addgrid.col = "gray",
tl.col = "black", tl.srt = 90, method = "color", tl.cex=0.5)
# We need to include the intercept when computing the VIF.
X.alt <- model.matrix(~.^2, data.frame(table2[,-1]))
# Variance-covariance matrix of 46-run design. Assuming sigma^2 = 1
var.eff.one <- diag(solve(t(X.alt)%*%X.alt))
View(table2)
View(X.alt)
knitr::opts_chunk$set(echo = TRUE)
library(AlgDesign)
library(FrF2)
library(corrplot)
library(randomForest)
factors <- list(ntree = c(100, 1000),
mtry = c(2, 6),
replace = c(0, 1),
nodesize = c(1,11),
classwt = c(0.5, 0.9),
cutoff = c(0.2, 0.8),
maxnodes = c(10, 1000))
my.design <- FrF2(nruns = 32, nfactors = 7, randomize = F, factor.names = factors)
print(my.design)
design.info(my.design)$catlg.entry
design.info(my.design)$aliased
# Create a full design for 7 factors each with 2 levels
full.design <- FrF2(nruns = 128, nfactors = 7, randomize = F, factor.names = factors)
# Consider a model with 35 runs
alternative.design <- optFederov(~.^2,
full.design, nTrials = 32, nRepeats = 1000)
print.data.frame(alternative.design$design)
# Visualize the aliasing in the design.
FD.alt <- (desnum(my.design)) # Extract the design.
# Create the model matrix including main effects and two-factor interactions.
FX.alt <- model.matrix(~., data.frame(FD.alt))
# Create color map on pairwise correlations.
contrast.vectors.correlations.alt <- cor(FX.alt)
corrplot(contrast.vectors.correlations.alt, type = "full", addgrid.col = "gray",
tl.col = "black", tl.srt = 90, method = "color", tl.cex=0.5)
# Visualize the aliasing in the design.
OD.alt <- alternative.design$design # Extract the design.
# Convert factors to -1 and 1
OD.alt <- sapply(OD.alt,function(x)(as.integer(x) -1.5)*2 )
OX.alt <- model.matrix(~., data.frame(OD.alt))
# Create color map on pairwise correlations.
contrast.vectors.correlations.alt <- cor(OX.alt)
corrplot(contrast.vectors.correlations.alt, type = "full", addgrid.col = "gray",
tl.col = "black", tl.srt = 90, method = "color", tl.cex=0.5)
# We need to include the intercept when computing the VIF.
X.alt <- model.matrix(~., data.frame(OD.alt))
# Variance-covariance matrix of 46-run design. Assuming sigma^2 = 1
var.eff.one <- diag(solve(t(X.alt)%*%X.alt))
# Set the left margin of plot be 1
par(oma=c(0,1,0,0))
#create horizontal bar chart to display each VIF value
barplot(nrow(X.alt)*var.eff.one, main = "VIF Values", horiz = TRUE, col = "cyan", las=1, cex.names=0.4, xlim = c(0, 6))
#add vertical line at 5
abline(v = 5, lwd = 3, lty = 2)
# Create the model matrix including main effects and two-factor interactions.
FX.alt <- model.matrix(~.^2-1, data.frame(FD.alt))
# Create color map on pairwise correlations.
contrast.vectors.correlations.alt <- cor(FX.alt)
corrplot(contrast.vectors.correlations.alt, type = "full", addgrid.col = "gray",
tl.col = "black", tl.srt = 90, method = "color", tl.cex=0.5)
OX.alt <- model.matrix(~.^2-1, data.frame(OD.alt))
# Create color map on pairwise correlations.
contrast.vectors.correlations.alt <- cor(OX.alt)
corrplot(contrast.vectors.correlations.alt, type = "full", addgrid.col = "gray",
tl.col = "black", tl.srt = 90, method = "color", tl.cex=0.5)
# We need to include the intercept when computing the VIF.
X.alt <- model.matrix(~.^2, data.frame(OD.alt))
# Variance-covariance matrix of 46-run design. Assuming sigma^2 = 1
var.eff.one <- diag(solve(t(X.alt)%*%X.alt))
# Set the left margin of plot be 1
par(oma=c(0,1,0,0))
#create horizontal bar chart to display each VIF value
barplot(nrow(X.alt)*var.eff.one, main = "VIF Values", horiz = TRUE, col = "cyan", las=1, cex.names=0.4, xlim = c(0, 6))
#add vertical line at 5
abline(v = 5, lwd = 3, lty = 2)
# We compare the run size of each runs for both designs
summary(as.data.frame(my.design))
summary(alternative.design$design)
table2 <- read.csv("Data/Alternative_Experimental_Design.csv")
head(table2)
# Convert factors to -1 and 1
table2 <- sapply(table2,function(x)(as.integer(as.factor(x)) -2) )
table2[,3][table2[,3]==0] <- 1
X.alt <- model.matrix(~.^2-1, data.frame(table2[,-1]))
# Create color map on pairwise correlations.
contrast.vectors.correlations.alt <- cor(X.alt)
corrplot(contrast.vectors.correlations.alt, type = "full", addgrid.col = "gray",
tl.col = "black", tl.srt = 90, method = "color", tl.cex=0.5)
# import function cv.rf(design, y, X)
source("CrossValidation_RandomForest/CrossValidation_RF.R")
# import dataset Cardiovascular
load("Data/cardiovascular.Rdata")
# convert the design from factor to numerical values
design.numerical <- as.data.frame(sapply(alternative.design$design, function(x) as.numeric(as.character(x))))
# randomize the run order
design.randomized <- design.numerical[sample(1:nrow(design.numerical)),]
head(design.randomized)
result <- cv.rf(design.randomized, y, X)
# save a copy of result thus no need to run cv.rf again
result.copy <- result
print(result)
# Converting numerical variables back to factors
str(result)
result[,c("ntree","mtry","replace",
"nodesize","classwt","cutoff","maxnodes")] <- lapply(result[,c("ntree","mtry","replace",
"nodesize","classwt","cutoff","maxnodes")],factor)
# Re-encoding Factors
levels(result$ntree) = c(-1,1)
levels(result$mtry) = c(-1,1)
levels(result$replace) = c(-1,1)
levels(result$nodesize) = c(-1,1)
levels(result$classwt) = c(-1,1)
levels(result$cutoff) = c(-1,1)
levels(result$maxnodes) = c(-1,1)
result <- as.data.frame(sapply(result, function(x) as.numeric(as.character(x))))
head(result)
# Running Linear Model
cv.model <- lm(CV~.^2, data=result.copy)
summary(cv.model)
library(leaps)
Best_Subset <- regsubsets(CV~.^2, data = result,
nbest = 1, nvmax=NULL,
force.in = NULL, force.out=NULL,
method = "exhaustive",
really.big=F)
summary_best_subset <- summary(Best_Subset)
plot(summary_best_subset$bic, xlab = "Number of Variables", ylab = "BIC", type = "l")
min = which.min(summary_best_subset$bic)
points(min, summary_best_subset$bic[min], col = "red", cex = 2, pch = 20)
### Select Model with least BIC score
# We first select the best model according to BIC.
modelwith.minimum.BIC <- which.min(summary_best_subset$bic)
best.model <- summary_best_subset$which[modelwith.minimum.BIC,][-1]
# Only keep the predictors are indicated by ‘TRUE’ and our response 'goldDiff'
keep <- names(best.model[best.model==T])
# Print the selected factors
a <- paste(keep,sep=" ",collapse=" + ")
a
# construct a reduced model based on BIC criteria
cv.model.bic <- lm(CV~classwt + cutoff + maxnodes + classwt:cutoff + classwt:maxnodes, data=result)
# T-test
summary(cv.model.bic)
# Analysis of Residuals
cv.res <- cv.model.bic$residuals
cv.fit <- cv.model.bic$fitted.values
par(mfrow = c(1,3))
qqnorm(cv.res)
qqline(cv.res)
plot(cv.fit,cv.res, main = "Residuals vs Fitted Values",
xlab = "Predicted", ylab = "Residuals")
N <- nrow(result)
plot(x = 1:N, y = cv.res, xlab = "Run Order",
ylab = "Residuals")
obj_func <- function(x){
pred.y <- 0.622765  - 0.048193 * x[5] + 0.028372 * x[6] + 0.015964*x[7] + 0.023461 *x[5]*x[6] + 0.037590 *x[5]*x[7]
return(-1*pred.y) # Because the 'optim' function minimizes.
}
# First, use optim() to find the optimal setting according to our model
optim(par = c(-1, -1, -1, -1,-1,-1,-1), fn = obj_func, lower = -1, upper = 1, method = "L-BFGS-B")
# Then, construct a dataframe of 7 columns, 1 row, with the optimal setting above
design.confirm <- data.frame(ntree = -1,
mtry = -1,
replace = -1,
nodesize = -1,
classwt = -1,
cutoff = 1,
maxnodes = -1)
head(design.confirm)
# Then, Get the prediction interval of the optimal setting based on our model
predict(cv.model.bic, newdata = design.confirm, interval = "predict")
# Convert the optimal setting to numerical values
design.confirm <- data.frame(ntree = rep(100,3),
mtry = rep(2,3),
replace = rep(0,3),
nodesize = rep(1,3),
classwt = rep(0.5,3),
cutoff = rep(0.8,3),
maxnodes = rep(10,3))
head(design.confirm)
# Lastly, run cv.rf() three times with optimal setting (with numerical data) to confirm
confirm.result <- cv.rf(design.confirm, y, X)
confirm.result$CV
mean(confirm.result$CV)
knitr::opts_chunk$set(echo = TRUE, eval=FALSE)
library(AlgDesign)
library(FrF2)
library(corrplot)
library(randomForest)
# Create the model matrix including main effects and two-factor interactions.
FX.alt <- model.matrix(~.^2, data.frame(FD.alt))
# Create color map on pairwise correlations.
contrast.vectors.correlations.alt <- cor(FX.alt)
corrplot(contrast.vectors.correlations.alt, type = "full", addgrid.col = "gray",
tl.col = "black", tl.srt = 90, method = "color", tl.cex=0.5)
